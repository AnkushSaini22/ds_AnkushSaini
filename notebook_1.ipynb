{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs('csv_files', exist_ok=True)\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "\n",
        "\n",
        "# Load raw data files\n",
        "print(\"Loading raw data...\")\n",
        "fear_greed = pd.read_csv('fear_greed_index - fear_greed_index.csv')\n",
        "print(f\"Fear & Greed Index loaded: {len(fear_greed)} records\")\n",
        "\n",
        "trades = pd.read_csv('historical_data - historical_data.csv')\n",
        "print(f\"Historical Trading Data loaded: {len(trades):,} records\")\n",
        "\n",
        "# Standardize data types for Fear & Greed Index\n",
        "print(\"Standardizing data types...\")\n",
        "fear_greed['date'] = pd.to_datetime(fear_greed['date'], errors='coerce')\n",
        "fear_greed['timestamp'] = pd.to_numeric(fear_greed['timestamp'], errors='coerce')\n",
        "fear_greed['value'] = pd.to_numeric(fear_greed['value'], errors='coerce')\n",
        "fear_greed['classification'] = fear_greed['classification'].astype('category')\n",
        "\n",
        "# Standardize timestamps in trading data\n",
        "trades['Timestamp IST'] = pd.to_datetime(trades['Timestamp IST'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
        "trades['date'] = trades['Timestamp IST'].dt.date\n",
        "trades['date'] = pd.to_datetime(trades['date'])\n",
        "trades['Timestamp'] = pd.to_numeric(trades['Timestamp'], errors='coerce')\n",
        "\n",
        "# Standardize numeric columns in trading data\n",
        "numeric_cols = ['Execution Price', 'Size Tokens', 'Size USD', 'Closed PnL',\n",
        "                'Fee', 'Start Position', 'Order ID', 'Trade ID']\n",
        "for col in numeric_cols:\n",
        "    if col in trades.columns:\n",
        "        trades[col] = pd.to_numeric(trades[col], errors='coerce')\n",
        "\n",
        "# Standardize categorical columns in trading data\n",
        "categorical_cols = ['Account', 'Coin', 'Side', 'Direction', 'Crossed']\n",
        "for col in categorical_cols:\n",
        "    if col in trades.columns:\n",
        "        trades[col] = trades[col].astype('category')\n",
        "\n",
        "print(\"Data types standardized\")\n",
        "\n",
        "# Handle missing values in Fear & Greed Index\n",
        "print(\"Handling missing values...\")\n",
        "fear_greed = fear_greed.dropna(subset=['date', 'value', 'classification'])\n",
        "print(f\"Fear & Greed cleaned: {len(fear_greed)} records\")\n",
        "\n",
        "# Handle missing values in trading data\n",
        "trades_before = len(trades)\n",
        "trades = trades.dropna(subset=['date', 'Account', 'Coin', 'Size USD'])\n",
        "trades['Closed PnL'] = trades['Closed PnL'].fillna(0)\n",
        "trades['Fee'] = trades['Fee'].fillna(0)\n",
        "print(f\"Trading data cleaned: {len(trades):,} records (removed {trades_before-len(trades):,})\")\n",
        "\n",
        "# Align timestamps and merge datasets\n",
        "print(\"Aligning timestamps and merging datasets...\")\n",
        "trades_aligned = pd.merge(trades, fear_greed[['date', 'value', 'classification']],\n",
        "                         on='date', how='inner')\n",
        "print(f\"Aligned dataset: {len(trades_aligned):,} records\")\n",
        "print(f\"Date range: {trades_aligned['date'].min()} to {trades_aligned['date'].max()}\")\n",
        "\n",
        "# Save cleaned data\n",
        "print(\"Saving cleaned data...\")\n",
        "fear_greed.to_csv('csv_files/cleaned_fear_greed_index.csv', index=False)\n",
        "trades.to_csv('csv_files/cleaned_trading_data.csv', index=False)\n",
        "trades_aligned.to_csv('csv_files/aligned_trades_sentiment.csv', index=False)\n",
        "print(\"All cleaned data saved to csv_files/\")\n",
        "\n",
        "print(\"STEP 3: EXPLORATORY DATA ANALYSIS\")\n",
        "\n",
        "# Calculate trader-level metrics\n",
        "print(\"Calculating trader metrics...\")\n",
        "trader_metrics = trades.groupby('Account').agg({\n",
        "    'Closed PnL': ['sum', 'mean', 'std', 'count'],\n",
        "    'Size USD': ['sum', 'mean', 'max'],\n",
        "    'Trade ID': 'count',\n",
        "    'Fee': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "trader_metrics.columns = ['Account', 'total_pnl', 'avg_pnl_per_trade', 'pnl_std',\n",
        "                          'trades_with_pnl', 'total_volume', 'avg_position_size',\n",
        "                          'max_position_size', 'total_trades', 'total_fees']\n",
        "\n",
        "# Calculate win rate for each trader\n",
        "trades_with_pnl = trades[trades['Closed PnL'] != 0].copy()\n",
        "winning_trades = trades_with_pnl[trades_with_pnl['Closed PnL'] > 0].groupby('Account').size()\n",
        "total_closed_trades = trades_with_pnl.groupby('Account').size()\n",
        "trader_metrics['win_rate'] = ((winning_trades / total_closed_trades) * 100).fillna(0)\n",
        "\n",
        "# Calculate additional performance metrics\n",
        "trader_metrics['profit_factor'] = trader_metrics['total_pnl'] / (trader_metrics['total_fees'] + 0.01)\n",
        "trader_metrics['sharpe_proxy'] = trader_metrics['total_pnl'] / (trader_metrics['pnl_std'] + 1)\n",
        "\n",
        "# Save trader metrics\n",
        "trader_metrics.to_csv('csv_files/trader_metrics.csv', index=False)\n",
        "print(f\"Trader metrics calculated for {len(trader_metrics)} traders\")\n",
        "print(\"Saved: csv_files/trader_metrics.csv\")\n",
        "\n",
        "# Calculate daily sentiment metrics\n",
        "print(\"Analyzing sentiment distribution...\")\n",
        "daily_sentiment_metrics = trades_aligned.groupby(['date', 'classification']).agg({\n",
        "    'Closed PnL': 'sum',\n",
        "    'Size USD': 'sum',\n",
        "    'Trade ID': 'count',\n",
        "    'Account': 'nunique'\n",
        "}).reset_index()\n",
        "\n",
        "daily_sentiment_metrics.columns = ['date', 'classification', 'daily_pnl',\n",
        "                                    'daily_volume', 'trade_count', 'active_traders']\n",
        "\n",
        "# Save daily sentiment metrics\n",
        "daily_sentiment_metrics.to_csv('csv_files/daily_sentiment_metrics.csv', index=False)\n",
        "print(\"Daily sentiment metrics calculated\")\n",
        "print(\"Saved: csv_files/daily_sentiment_metrics.csv\")\n",
        "\n",
        "# Display sentiment distribution\n",
        "sentiment_dist = trades_aligned['classification'].value_counts()\n",
        "print(\"Sentiment Distribution:\")\n",
        "for sentiment, count in sentiment_dist.items():\n",
        "    pct = (count / len(trades_aligned)) * 100\n",
        "    print(f\"  {sentiment:15s}: {count:7,} trades ({pct:5.2f}%)\")\n",
        "\n",
        "# Create visualizations\n",
        "print(\"Creating visualizations...\")\n",
        "\n",
        "# Visualization 1: Sentiment distribution pie chart\n",
        "print(\"1. Creating sentiment distribution pie chart...\")\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "colors = ['#e74c3c', '#f39c12', '#95a5a6', '#3498db', '#2ecc71']\n",
        "sentiment_dist.plot(kind='pie', autopct='%1.1f%%', colors=colors, ax=ax)\n",
        "ax.set_title('Sentiment Distribution Across All Trades', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_ylabel('')\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/1_sentiment_distribution.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  Saved: outputs/1_sentiment_distribution.png\")\n",
        "\n",
        "# Visualization 2: Top 10 traders by PnL\n",
        "print(\"2. Creating top traders chart...\")\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "top10_traders = trader_metrics.nlargest(10, 'total_pnl')\n",
        "trader_labels = [f\"Trader {i+1}\" for i in range(len(top10_traders))]\n",
        "bars = ax.barh(trader_labels, top10_traders['total_pnl'].values, color='#3498db')\n",
        "ax.set_xlabel('Total PnL ($)', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Traders', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Top 10 Traders by Total PnL', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "for bar, val in zip(bars, top10_traders['total_pnl'].values):\n",
        "    ax.text(val, bar.get_y() + bar.get_height()/2, f'${val:,.0f}',\n",
        "            va='center', ha='left', fontsize=10, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/2_top_traders_pnl.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  Saved: outputs/2_top_traders_pnl.png\")\n",
        "\n",
        "# Visualization 3: PnL by sentiment\n",
        "print(\"3. Creating PnL by sentiment chart...\")\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "sentiment_pnl = trades_aligned.groupby('classification')['Closed PnL'].sum().sort_values(ascending=False)\n",
        "colors_map = {'Extreme Fear': '#e74c3c', 'Fear': '#f39c12', 'Neutral': '#95a5a6',\n",
        "              'Greed': '#3498db', 'Extreme Greed': '#2ecc71'}\n",
        "bar_colors = [colors_map.get(s, '#95a5a6') for s in sentiment_pnl.index]\n",
        "bars = ax.bar(sentiment_pnl.index, sentiment_pnl.values, color=bar_colors,\n",
        "              edgecolor='black', linewidth=1.5)\n",
        "ax.set_ylabel('Total PnL ($)', fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('Sentiment Category', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Total PnL by Market Sentiment', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'${height:,.0f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/3_pnl_by_sentiment.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  Saved: outputs/3_pnl_by_sentiment.png\")\n",
        "\n",
        "# Visualization 4: Position size by sentiment\n",
        "print(\"4. Creating position sizing chart...\")\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "position_by_sentiment = trades_aligned.groupby('classification')['Size USD'].agg(['mean', 'median'])\n",
        "position_by_sentiment = position_by_sentiment.sort_values('mean', ascending=False)\n",
        "x = np.arange(len(position_by_sentiment))\n",
        "width = 0.35\n",
        "bars1 = ax.bar(x - width/2, position_by_sentiment['mean'], width,\n",
        "               label='Mean', color='#3498db', alpha=0.8)\n",
        "bars2 = ax.bar(x + width/2, position_by_sentiment['median'], width,\n",
        "               label='Median', color='#e74c3c', alpha=0.8)\n",
        "ax.set_ylabel('Position Size ($)', fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('Sentiment Category', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Average Position Sizing by Market Sentiment', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(position_by_sentiment.index, rotation=45, ha='right')\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/4_position_size_by_sentiment.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  Saved: outputs/4_position_size_by_sentiment.png\")\n",
        "\n",
        "# Visualization 5: Daily volume time series\n",
        "print(\"5. Creating daily volume time series...\")\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "daily_volume = trades_aligned.groupby('date')['Size USD'].sum()\n",
        "ax.plot(daily_volume.index, daily_volume.values, linewidth=2, color='#3498db', alpha=0.7)\n",
        "ax.fill_between(daily_volume.index, daily_volume.values, alpha=0.3, color='#3498db')\n",
        "ax.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Daily Volume ($)', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Daily Trading Volume Over Time', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/5_daily_volume_timeseries.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  Saved: outputs/5_daily_volume_timeseries.png\")\n",
        "\n",
        "# Visualization 6: Sentiment timeline\n",
        "print(\"6. Creating sentiment timeline...\")\n",
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "sentiment_daily = trades_aligned.groupby(['date', 'classification']).size().unstack(fill_value=0)\n",
        "sentiment_daily.plot(kind='area', stacked=True, ax=ax,\n",
        "                     color=['#e74c3c', '#f39c12', '#95a5a6', '#3498db', '#2ecc71'],\n",
        "                     alpha=0.7)\n",
        "ax.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Number of Trades', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Trading Activity Timeline by Sentiment', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.legend(title='Sentiment', fontsize=10, title_fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/6_sentiment_timeline.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  Saved: outputs/6_sentiment_timeline.png\")\n",
        "\n",
        "# Visualization 7: Position size distribution\n",
        "print(\"7. Creating position size distribution...\")\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "position_cap = trades_aligned['Size USD'].quantile(0.99)\n",
        "filtered_positions = trades_aligned[trades_aligned['Size USD'] <= position_cap]['Size USD']\n",
        "ax.hist(filtered_positions, bins=50, color='#3498db', alpha=0.7, edgecolor='black')\n",
        "ax.set_xlabel('Position Size ($)', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Distribution of Position Sizes (up to 99th percentile)',\n",
        "             fontsize=16, fontweight='bold', pad=20)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "mean_pos = filtered_positions.mean()\n",
        "median_pos = filtered_positions.median()\n",
        "ax.axvline(mean_pos, color='red', linestyle='--', linewidth=2,\n",
        "           label=f'Mean: ${mean_pos:,.2f}')\n",
        "ax.axvline(median_pos, color='green', linestyle='--', linewidth=2,\n",
        "           label=f'Median: ${median_pos:,.2f}')\n",
        "ax.legend(fontsize=11)\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/7_position_size_distribution.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  Saved: outputs/7_position_size_distribution.png\")\n",
        "\n",
        "# Visualization 8: Trader performance scatter\n",
        "print(\"8. Creating trader performance scatter...\")\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "scatter = ax.scatter(trader_metrics['total_volume'],\n",
        "                    trader_metrics['total_pnl'],\n",
        "                    s=trader_metrics['total_trades']/50,\n",
        "                    c=trader_metrics['total_pnl'],\n",
        "                    cmap='RdYlGn',\n",
        "                    alpha=0.6,\n",
        "                    edgecolors='black',\n",
        "                    linewidth=1)\n",
        "ax.set_xlabel('Total Volume ($)', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Total PnL ($)', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Trader Performance: Volume vs Profitability',\n",
        "             fontsize=16, fontweight='bold', pad=20)\n",
        "ax.grid(True, alpha=0.3)\n",
        "cbar = plt.colorbar(scatter, ax=ax)\n",
        "cbar.set_label('Total PnL ($)', fontsize=11, fontweight='bold')\n",
        "ax.axhline(y=0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/8_trader_performance_scatter.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  Saved: outputs/8_trader_performance_scatter.png\")\n",
        "\n",
        "# Print summary\n",
        "print(\"ANALYSIS COMPLETE\")\n",
        "print(\"CSV Files Created (csv_files/):\")\n",
        "print(\"  1. cleaned_fear_greed_index.csv\")\n",
        "print(\"  2. cleaned_trading_data.csv\")\n",
        "print(\"  3. aligned_trades_sentiment.csv\")\n",
        "print(\"  4. trader_metrics.csv\")\n",
        "print(\"  5. daily_sentiment_metrics.csv\")\n",
        "print(\"Visualizations Created (outputs/):\")\n",
        "print(\"  1. sentiment_distribution.png\")\n",
        "print(\"  2. top_traders_pnl.png\")\n",
        "print(\"  3. pnl_by_sentiment.png\")\n",
        "print(\"  4. position_size_by_sentiment.png\")\n",
        "print(\"  5. daily_volume_timeseries.png\")\n",
        "print(\"  6. sentiment_timeline.png\")\n",
        "print(\"  7. position_size_distribution.png\")\n",
        "print(\"  8. trader_performance_scatter.png\")\n",
        "print(\"Ready for submission\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esadb_h_ZNjw",
        "outputId": "57775877-812d-43e1-d669-5db2e965c348"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading raw data...\n",
            "Fear & Greed Index loaded: 2644 records\n",
            "Historical Trading Data loaded: 211,224 records\n",
            "Standardizing data types...\n",
            "Data types standardized\n",
            "Handling missing values...\n",
            "Fear & Greed cleaned: 2644 records\n",
            "Trading data cleaned: 211,224 records (removed 0)\n",
            "Aligning timestamps and merging datasets...\n",
            "Aligned dataset: 211,218 records\n",
            "Date range: 2023-05-01 00:00:00 to 2025-05-01 00:00:00\n",
            "Saving cleaned data...\n",
            "All cleaned data saved to csv_files/\n",
            "STEP 3: EXPLORATORY DATA ANALYSIS\n",
            "Calculating trader metrics...\n",
            "Trader metrics calculated for 32 traders\n",
            "Saved: csv_files/trader_metrics.csv\n",
            "Analyzing sentiment distribution...\n",
            "Daily sentiment metrics calculated\n",
            "Saved: csv_files/daily_sentiment_metrics.csv\n",
            "Sentiment Distribution:\n",
            "  Fear           :  61,837 trades (29.28%)\n",
            "  Greed          :  50,303 trades (23.82%)\n",
            "  Extreme Greed  :  39,992 trades (18.93%)\n",
            "  Neutral        :  37,686 trades (17.84%)\n",
            "  Extreme Fear   :  21,400 trades (10.13%)\n",
            "Creating visualizations...\n",
            "1. Creating sentiment distribution pie chart...\n",
            "  Saved: outputs/1_sentiment_distribution.png\n",
            "2. Creating top traders chart...\n",
            "  Saved: outputs/2_top_traders_pnl.png\n",
            "3. Creating PnL by sentiment chart...\n",
            "  Saved: outputs/3_pnl_by_sentiment.png\n",
            "4. Creating position sizing chart...\n",
            "  Saved: outputs/4_position_size_by_sentiment.png\n",
            "5. Creating daily volume time series...\n",
            "  Saved: outputs/5_daily_volume_timeseries.png\n",
            "6. Creating sentiment timeline...\n",
            "  Saved: outputs/6_sentiment_timeline.png\n",
            "7. Creating position size distribution...\n",
            "  Saved: outputs/7_position_size_distribution.png\n",
            "8. Creating trader performance scatter...\n",
            "  Saved: outputs/8_trader_performance_scatter.png\n",
            "ANALYSIS COMPLETE\n",
            "CSV Files Created (csv_files/):\n",
            "  1. cleaned_fear_greed_index.csv\n",
            "  2. cleaned_trading_data.csv\n",
            "  3. aligned_trades_sentiment.csv\n",
            "  4. trader_metrics.csv\n",
            "  5. daily_sentiment_metrics.csv\n",
            "Visualizations Created (outputs/):\n",
            "  1. sentiment_distribution.png\n",
            "  2. top_traders_pnl.png\n",
            "  3. pnl_by_sentiment.png\n",
            "  4. position_size_by_sentiment.png\n",
            "  5. daily_volume_timeseries.png\n",
            "  6. sentiment_timeline.png\n",
            "  7. position_size_distribution.png\n",
            "  8. trader_performance_scatter.png\n",
            "Ready for submission\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from statsmodels.tsa.stattools import grangercausalitytests, adfuller\n",
        "from scipy import signal\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load cleaned data from previous steps\n",
        "print(\"Loading cleaned data...\")\n",
        "trades_aligned = pd.read_csv('csv_files/aligned_trades_sentiment.csv')\n",
        "trades_aligned['date'] = pd.to_datetime(trades_aligned['date'])\n",
        "trader_metrics = pd.read_csv('csv_files/trader_metrics.csv')\n",
        "print(f\"Loaded {len(trades_aligned):,} trades\")\n",
        "print(f\"Loaded {len(trader_metrics)} trader profiles\")\n",
        "\n",
        "print(\"SENTIMENT-BEHAVIOR CORRELATION\")\n",
        "\n",
        "# Calculate daily aggregated performance by sentiment\n",
        "print(\"Profitability Analysis by Sentiment\")\n",
        "daily_perf = trades_aligned.groupby(['date', 'classification']).agg({\n",
        "    'Closed PnL': ['sum', 'mean', 'count'],\n",
        "    'Size USD': ['sum', 'mean'],\n",
        "    'Fee': 'sum',\n",
        "    'Account': 'nunique'\n",
        "}).reset_index()\n",
        "\n",
        "daily_perf.columns = ['date', 'classification', 'total_pnl', 'avg_pnl', 'trade_count',\n",
        "                      'total_volume', 'avg_position', 'total_fees', 'active_traders']\n",
        "\n",
        "# Compare Fear vs Greed profitability\n",
        "fear_profit = daily_perf[daily_perf['classification'] == 'Fear']['total_pnl']\n",
        "greed_profit = daily_perf[daily_perf['classification'] == 'Greed']['total_pnl']\n",
        "\n",
        "print(\"Fear Periods:\")\n",
        "print(f\"  Avg Daily PnL: ${fear_profit.mean():,.2f}\")\n",
        "print(f\"  Median Daily PnL: ${fear_profit.median():,.2f}\")\n",
        "print(f\"  Std Dev: ${fear_profit.std():,.2f}\")\n",
        "\n",
        "print(\"Greed Periods:\")\n",
        "print(f\"  Avg Daily PnL: ${greed_profit.mean():,.2f}\")\n",
        "print(f\"  Median Daily PnL: ${greed_profit.median():,.2f}\")\n",
        "print(f\"  Std Dev: ${greed_profit.std():,.2f}\")\n",
        "\n",
        "# Statistical test: T-test\n",
        "t_stat, p_value = stats.ttest_ind(fear_profit.dropna(), greed_profit.dropna())\n",
        "print(\"T-Test (Fear vs Greed):\")\n",
        "print(f\"  t-statistic: {t_stat:.4f}\")\n",
        "print(f\"  p-value: {p_value:.6f}\")\n",
        "if p_value < 0.05:\n",
        "    print(\"  SIGNIFICANT difference (p < 0.05)\")\n",
        "else:\n",
        "    print(\"  Not significant (p >= 0.05)\")\n",
        "\n",
        "# Save correlation results\n",
        "correlation_results = daily_perf.groupby('classification').agg({\n",
        "    'total_pnl': ['mean', 'median', 'std'],\n",
        "    'total_volume': 'mean',\n",
        "    'avg_position': 'mean',\n",
        "    'active_traders': 'mean'\n",
        "}).round(2)\n",
        "correlation_results.to_csv('csv_files/sentiment_correlation_results.csv')\n",
        "print(\"Saved: csv_files/sentiment_correlation_results.csv\")\n",
        "\n",
        "# Volume patterns before sentiment shifts\n",
        "print(\" Volume Patterns Before Sentiment Shifts\")\n",
        "daily_sentiment = trades_aligned.groupby('date')['classification'].first().reset_index()\n",
        "daily_sentiment['sentiment_shift'] = daily_sentiment['classification'] != daily_sentiment['classification'].shift(1)\n",
        "shift_dates = daily_sentiment[daily_sentiment['sentiment_shift']]['date'].values\n",
        "\n",
        "# Calculate volume 3 days before each shift\n",
        "volume_before_shift = []\n",
        "for shift_date in shift_dates:\n",
        "    shift_dt = pd.to_datetime(shift_date)\n",
        "    pre_period = trades_aligned[\n",
        "        (trades_aligned['date'] >= shift_dt - pd.Timedelta(days=3)) &\n",
        "        (trades_aligned['date'] < shift_dt)\n",
        "    ]['Size USD'].sum()\n",
        "    volume_before_shift.append(pre_period)\n",
        "\n",
        "normal_volume = trades_aligned.groupby('date')['Size USD'].sum().mean()\n",
        "avg_pre_shift_volume = np.mean(volume_before_shift) if volume_before_shift else 0\n",
        "\n",
        "print(\"Volume Analysis:\")\n",
        "print(f\"  Normal Daily Volume: ${normal_volume:,.2f}\")\n",
        "print(f\"  Avg Volume 3-days Before Shift: ${avg_pre_shift_volume:,.2f}\")\n",
        "print(f\"  Ratio: {avg_pre_shift_volume/normal_volume:.2f}x\")\n",
        "\n",
        "if avg_pre_shift_volume > normal_volume * 1.2:\n",
        "    print(\"  VOLUME SURGE detected before sentiment shifts (+20%)\")\n",
        "else:\n",
        "    print(\"  No significant volume change before shifts\")\n",
        "\n",
        "# Granger causality test\n",
        "print(\"Advanced: Granger Causality Test\")\n",
        "ts_data = trades_aligned.groupby('date').agg({\n",
        "    'Closed PnL': 'sum',\n",
        "    'value': 'first'\n",
        "}).reset_index()\n",
        "ts_data.columns = ['date', 'daily_pnl', 'sentiment_value']\n",
        "\n",
        "# Check stationarity\n",
        "adf_pnl = adfuller(ts_data['daily_pnl'].dropna())\n",
        "adf_sentiment = adfuller(ts_data['sentiment_value'].dropna())\n",
        "\n",
        "print(\"Stationarity Tests:\")\n",
        "print(f\"  PnL: ADF={adf_pnl[0]:.4f}, p-value={adf_pnl[1]:.4f}\")\n",
        "print(f\"  Sentiment: ADF={adf_sentiment[0]:.4f}, p-value={adf_sentiment[1]:.4f}\")\n",
        "\n",
        "# Difference if needed for stationarity\n",
        "if adf_pnl[1] > 0.05:\n",
        "    ts_data['daily_pnl'] = ts_data['daily_pnl'].diff()\n",
        "if adf_sentiment[1] > 0.05:\n",
        "    ts_data['sentiment_value'] = ts_data['sentiment_value'].diff()\n",
        "\n",
        "ts_data = ts_data.dropna()\n",
        "\n",
        "# Run Granger test\n",
        "if len(ts_data) > 50:\n",
        "    try:\n",
        "        gc_result = grangercausalitytests(ts_data[['daily_pnl', 'sentiment_value']],\n",
        "                                          maxlag=5, verbose=False)\n",
        "\n",
        "        print(\"Granger Causality Results:\")\n",
        "        for lag in [1, 2, 3]:\n",
        "            p_val = gc_result[lag][0]['ssr_ftest'][1]\n",
        "            causal = \"YES\" if p_val < 0.05 else \"NO\"\n",
        "            print(f\"  Lag {lag}: p-value={p_val:.4f} | Causal: {causal}\")\n",
        "\n",
        "        best_lag = min(gc_result.keys(), key=lambda x: gc_result[x][0]['ssr_ftest'][1])\n",
        "        print(f\"  Best predictive lag: {best_lag} days\")\n",
        "    except Exception as e:\n",
        "        print(f\"  Note: {str(e)[:80]}\")\n",
        "\n",
        "# Cross-correlation analysis\n",
        "print(\" Cross-Correlation (Lead-Lag Analysis)\")\n",
        "\n",
        "def calculate_cross_corr(series1, series2, max_lag=10):\n",
        "    s1 = (series1 - np.mean(series1)) / (np.std(series1) * len(series1))\n",
        "    s2 = (series2 - np.mean(series2)) / np.std(series2)\n",
        "    ccf = np.correlate(s1, s2, 'full')\n",
        "    lags = signal.correlation_lags(len(series1), len(series2))\n",
        "    center = len(ccf) // 2\n",
        "    return lags[center-max_lag:center+max_lag+1], ccf[center-max_lag:center+max_lag+1]\n",
        "\n",
        "ts_fresh = trades_aligned.groupby('date').agg({\n",
        "    'Closed PnL': 'sum',\n",
        "    'value': 'first'\n",
        "}).reset_index()\n",
        "\n",
        "lags, ccf = calculate_cross_corr(ts_fresh['value'].values,\n",
        "                                  ts_fresh['Closed PnL'].values,\n",
        "                                  max_lag=7)\n",
        "\n",
        "max_corr_idx = np.argmax(np.abs(ccf))\n",
        "optimal_lag = lags[max_corr_idx]\n",
        "max_corr = ccf[max_corr_idx]\n",
        "\n",
        "print(\"Cross-Correlation Results:\")\n",
        "print(f\"  Maximum correlation: {max_corr:.4f} at lag {optimal_lag} days\")\n",
        "if optimal_lag < 0:\n",
        "    print(f\"  Sentiment LEADS profitability by {abs(optimal_lag)} days\")\n",
        "elif optimal_lag > 0:\n",
        "    print(f\"  Profitability LEADS sentiment by {optimal_lag} days\")\n",
        "else:\n",
        "    print(f\"  Contemporaneous relationship (same day)\")\n",
        "\n",
        "print(\" PATTERN DISCOVERY & INSIGHTS\")\n",
        "\n",
        "# K-Means clustering\n",
        "print(\"K-Means Clustering (Basic)\")\n",
        "features_df = trader_metrics[['total_pnl', 'avg_position_size', 'total_trades',\n",
        "                               'total_volume', 'profit_factor']].fillna(0)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features_df)\n",
        "\n",
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "trader_metrics['cluster_kmeans'] = kmeans.fit_predict(features_scaled)\n",
        "\n",
        "print(\"K-Means clustering complete\")\n",
        "print(\"Cluster Distribution:\")\n",
        "print(trader_metrics['cluster_kmeans'].value_counts().sort_index())\n",
        "\n",
        "cluster_profiles = trader_metrics.groupby('cluster_kmeans').agg({\n",
        "    'total_pnl': ['mean', 'sum'],\n",
        "    'total_trades': 'mean',\n",
        "    'avg_position_size': 'mean',\n",
        "    'total_volume': 'mean',\n",
        "    'Account': 'count'\n",
        "}).round(2)\n",
        "\n",
        "print(\"Cluster Profiles:\")\n",
        "print(cluster_profiles)\n",
        "\n",
        "# Characterize each cluster\n",
        "for cluster_id in range(3):\n",
        "    cluster_data = trader_metrics[trader_metrics['cluster_kmeans'] == cluster_id]\n",
        "    avg_trades = cluster_data['total_trades'].mean()\n",
        "    avg_pos = cluster_data['avg_position_size'].mean()\n",
        "\n",
        "    if avg_trades > 15000:\n",
        "        profile = \"HIGH FREQUENCY SCALPERS\"\n",
        "    elif avg_pos > 15000:\n",
        "        profile = \"WHALE TRADERS (Large Positions)\"\n",
        "    else:\n",
        "        profile = \"BALANCED TRADERS\"\n",
        "\n",
        "    print(f\"  Cluster {cluster_id}: {profile}\")\n",
        "    print(f\"    Members: {len(cluster_data)}\")\n",
        "    print(f\"    Avg PnL: ${cluster_data['total_pnl'].mean():,.2f}\")\n",
        "\n",
        "# DBSCAN clustering\n",
        "print(\"DBSCAN Clustering (Advanced - Density-based)\")\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=2)\n",
        "trader_metrics['cluster_dbscan'] = dbscan.fit_predict(features_scaled)\n",
        "\n",
        "n_clusters = len(set(trader_metrics['cluster_dbscan'])) - (1 if -1 in trader_metrics['cluster_dbscan'] else 0)\n",
        "n_outliers = (trader_metrics['cluster_dbscan'] == -1).sum()\n",
        "\n",
        "print(\"DBSCAN clustering complete\")\n",
        "print(f\"  Clusters found: {n_clusters}\")\n",
        "print(f\"  Outliers detected: {n_outliers}\")\n",
        "\n",
        "if n_outliers > 0:\n",
        "    outliers = trader_metrics[trader_metrics['cluster_dbscan'] == -1]\n",
        "    print(\"  Outlier traders (exceptional performance):\")\n",
        "    for idx, row in outliers.nlargest(3, 'total_pnl').iterrows():\n",
        "        print(f\"    Account {row['Account'][:12]}...: ${row['total_pnl']:,.2f}\")\n",
        "\n",
        "# PCA analysis\n",
        "print(\" PCA Analysis (Advanced)\")\n",
        "pca = PCA(n_components=2)\n",
        "pca_features = pca.fit_transform(features_scaled)\n",
        "trader_metrics['pca1'] = pca_features[:, 0]\n",
        "trader_metrics['pca2'] = pca_features[:, 1]\n",
        "\n",
        "explained_var = pca.explained_variance_ratio_\n",
        "print(\"PCA complete\")\n",
        "print(f\"  PC1 explains: {explained_var[0]*100:.2f}% variance\")\n",
        "print(f\"  PC2 explains: {explained_var[1]*100:.2f}% variance\")\n",
        "print(f\"  Total explained: {sum(explained_var)*100:.2f}%\")\n",
        "\n",
        "# Profitable trader behavior extraction\n",
        "print(\" Profitable Trader Patterns\")\n",
        "profit_threshold = trader_metrics['total_pnl'].quantile(0.75)\n",
        "trader_metrics['is_profitable'] = trader_metrics['total_pnl'] > profit_threshold\n",
        "\n",
        "profitable_traders = trader_metrics[trader_metrics['is_profitable']]\n",
        "unprofitable_traders = trader_metrics[~trader_metrics['is_profitable']]\n",
        "\n",
        "print(\"Comparison: Profitable vs Others\")\n",
        "print(f\"  Profitable Traders: {len(profitable_traders)}\")\n",
        "print(f\"  Others: {len(unprofitable_traders)}\")\n",
        "\n",
        "comparison_metrics = {\n",
        "    'Avg Position Size': [profitable_traders['avg_position_size'].mean(),\n",
        "                          unprofitable_traders['avg_position_size'].mean()],\n",
        "    'Avg Trade Count': [profitable_traders['total_trades'].mean(),\n",
        "                        unprofitable_traders['total_trades'].mean()],\n",
        "    'Avg Volume': [profitable_traders['total_volume'].mean(),\n",
        "                   unprofitable_traders['total_volume'].mean()],\n",
        "    'Profit Factor': [profitable_traders['profit_factor'].mean(),\n",
        "                      unprofitable_traders['profit_factor'].mean()]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_metrics,\n",
        "                             index=['Profitable (Top 25%)', 'Others']).T\n",
        "print(comparison_df)\n",
        "\n",
        "# Statistical significance tests\n",
        "print(\" Statistical Significance Tests\")\n",
        "\n",
        "# Test 1: Mann-Whitney U test\n",
        "stat_pos, p_pos = stats.mannwhitneyu(\n",
        "    profitable_traders['avg_position_size'],\n",
        "    unprofitable_traders['avg_position_size']\n",
        ")\n",
        "print(\"Position Size Difference:\")\n",
        "print(f\"  Mann-Whitney U: {stat_pos:.2f}\")\n",
        "print(f\"  p-value: {p_pos:.6f}\")\n",
        "print(f\"  Result: {'SIGNIFICANT' if p_pos < 0.05 else 'Not Significant'}\")\n",
        "\n",
        "# Test 2: Chi-Square test\n",
        "sentiment_by_profit = pd.crosstab(\n",
        "    trades_aligned['Account'].isin(profitable_traders['Account']),\n",
        "    trades_aligned['classification']\n",
        ")\n",
        "chi2, p_chi2, dof, expected = stats.chi2_contingency(sentiment_by_profit)\n",
        "print(\"Sentiment Association with Profitability:\")\n",
        "print(f\"  Chi-Square: {chi2:.2f}\")\n",
        "print(f\"  p-value: {p_chi2:.6f}\")\n",
        "print(f\"  Result: {'SIGNIFICANT' if p_chi2 < 0.05 else 'Not Significant'}\")\n",
        "\n",
        "# Test 3: ANOVA\n",
        "clusters_list = [trader_metrics[trader_metrics['cluster_kmeans'] == i]['total_pnl']\n",
        "                 for i in range(3)]\n",
        "f_stat, p_anova = stats.f_oneway(*clusters_list)\n",
        "print(\"Cluster Performance Difference:\")\n",
        "print(f\"  F-statistic: {f_stat:.2f}\")\n",
        "print(f\"  p-value: {p_anova:.6f}\")\n",
        "print(f\"  Result: {'SIGNIFICANT' if p_anova < 0.05 else 'Not Significant'}\")\n",
        "\n",
        "# Behavioral patterns by sentiment\n",
        "print(\" Behavioral Patterns in Different Market Conditions\")\n",
        "trades_with_profit = trades_aligned.merge(\n",
        "    trader_metrics[['Account', 'is_profitable']],\n",
        "    on='Account',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "behavior_patterns = trades_with_profit.groupby(['classification', 'is_profitable']).agg({\n",
        "    'Size USD': 'mean',\n",
        "    'Trade ID': 'count',\n",
        "    'Closed PnL': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "print(\"Average Position Size by Sentiment & Profitability:\")\n",
        "print(behavior_patterns['Size USD'].unstack())\n",
        "\n",
        "print(\"Trade Frequency by Sentiment & Profitability:\")\n",
        "print(behavior_patterns['Trade ID'].unstack())\n",
        "\n",
        "# Save results\n",
        "print(\"Saving results...\")\n",
        "trader_metrics.to_csv('csv_files/trader_metrics_clustered.csv', index=False)\n",
        "print(\"Saved: csv_files/trader_metrics_clustered.csv\")\n",
        "\n",
        "behavior_patterns.to_csv('csv_files/behavioral_patterns.csv')\n",
        "print(\"Saved: csv_files/behavioral_patterns.csv\")\n",
        "\n",
        "comparison_df.to_csv('csv_files/profitable_comparison.csv')\n",
        "print(\"Saved: csv_files/profitable_comparison.csv\")\n",
        "\n",
        "# Create visualizations\n",
        "print(\"Creating visualizations...\")\n",
        "\n",
        "# Visualization 1: PnL by sentiment box plot\n",
        "print(\"1. Creating sentiment profitability boxplot...\")\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "sentiment_order = ['Extreme Fear', 'Fear', 'Neutral', 'Greed', 'Extreme Greed']\n",
        "sns.boxplot(data=daily_perf, x='classification', y='total_pnl',\n",
        "            order=sentiment_order, palette='Set2', ax=ax)\n",
        "ax.set_xlabel('Sentiment Category', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Daily Total PnL ($)', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Profitability Distribution by Market Sentiment',\n",
        "             fontsize=16, fontweight='bold', pad=20)\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/9_sentiment_profitability_boxplot.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  Saved: outputs/9_sentiment_profitability_boxplot.png\")\n",
        "\n",
        "# Visualization 2: Cluster visualization with PCA\n",
        "print(\"2. Creating trader clusters PCA plot...\")\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
        "for i in range(3):\n",
        "    cluster_data = trader_metrics[trader_metrics['cluster_kmeans'] == i]\n",
        "    ax.scatter(cluster_data['pca1'], cluster_data['pca2'],\n",
        "              c=colors[i], label=f'Cluster {i}', s=100, alpha=0.6, edgecolors='black')\n",
        "ax.set_xlabel(f'PC1 ({explained_var[0]*100:.1f}% variance)', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel(f'PC2 ({explained_var[1]*100:.1f}% variance)', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Trader Clusters (PCA Visualization)', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/10_trader_clusters_pca.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  Saved: outputs/10_trader_clusters_pca.png\")\n",
        "\n",
        "# Visualization 3: Profitable vs others comparison\n",
        "print(\"3. Creating profitable comparison chart...\")\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "comparison_df.plot(kind='bar', ax=ax, color=['#2ecc71', '#e74c3c'], alpha=0.8)\n",
        "ax.set_xlabel('Metrics', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Value', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Profitable Traders vs Others: Key Metrics Comparison',\n",
        "             fontsize=16, fontweight='bold', pad=20)\n",
        "ax.legend(['Profitable (Top 25%)', 'Others'], fontsize=11)\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/11_profitable_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  Saved: outputs/11_profitable_comparison.png\")\n",
        "\n",
        "# Visualization 4: Volume before sentiment shifts\n",
        "print(\"4. Creating volume sentiment shift chart...\")\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "categories = ['Normal Days', '3-Days Before Sentiment Shift']\n",
        "volumes = [normal_volume, avg_pre_shift_volume]\n",
        "bars = ax.bar(categories, volumes, color=['#3498db', '#e74c3c'], alpha=0.8,\n",
        "              edgecolor='black', linewidth=2)\n",
        "ax.set_ylabel('Average Daily Volume ($)', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Trading Volume: Normal vs Pre-Sentiment Shift',\n",
        "             fontsize=16, fontweight='bold', pad=20)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "for bar, vol in zip(bars, volumes):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'${vol:,.0f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/12_volume_sentiment_shift.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  Saved: outputs/12_volume_sentiment_shift.png\")\n",
        "\n",
        "print(\"STEPS 4 & 5 COMPLETE\")\n",
        "print(\"New CSV Files:\")\n",
        "print(\"  - sentiment_correlation_results.csv\")\n",
        "print(\"  - trader_metrics_clustered.csv\")\n",
        "print(\"  - behavioral_patterns.csv\")\n",
        "print(\"  - profitable_comparison.csv\")\n",
        "print(\"New Visualizations:\")\n",
        "print(\"  - 9_sentiment_profitability_boxplot.png\")\n",
        "print(\"  - 10_trader_clusters_pca.png\")\n",
        "print(\"  - 11_profitable_comparison.png\")\n",
        "print(\"  - 12_volume_sentiment_shift.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYNsFKMEZNcZ",
        "outputId": "05050e45-c198-4291-d905-d2701280959e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cleaned data...\n",
            "Loaded 211,218 trades\n",
            "Loaded 32 trader profiles\n",
            "SENTIMENT-BEHAVIOR CORRELATION\n",
            "Profitability Analysis by Sentiment\n",
            "Fear Periods:\n",
            "  Avg Daily PnL: $36,891.82\n",
            "  Median Daily PnL: $1,412.31\n",
            "  Std Dev: $96,611.85\n",
            "Greed Periods:\n",
            "  Avg Daily PnL: $11,140.57\n",
            "  Median Daily PnL: $678.48\n",
            "  Std Dev: $62,427.96\n",
            "T-Test (Fear vs Greed):\n",
            "  t-statistic: 2.6983\n",
            "  p-value: 0.007389\n",
            "  SIGNIFICANT difference (p < 0.05)\n",
            "Saved: csv_files/sentiment_correlation_results.csv\n",
            " Volume Patterns Before Sentiment Shifts\n",
            "Volume Analysis:\n",
            "  Normal Daily Volume: $2,486,636.27\n",
            "  Avg Volume 3-days Before Shift: $9,400,344.29\n",
            "  Ratio: 3.78x\n",
            "  VOLUME SURGE detected before sentiment shifts (+20%)\n",
            "Advanced: Granger Causality Test\n",
            "Stationarity Tests:\n",
            "  PnL: ADF=-4.0488, p-value=0.0012\n",
            "  Sentiment: ADF=-3.1799, p-value=0.0212\n",
            "Granger Causality Results:\n",
            "  Lag 1: p-value=0.0597 | Causal: NO\n",
            "  Lag 2: p-value=0.0372 | Causal: YES\n",
            "  Lag 3: p-value=0.1110 | Causal: NO\n",
            "  Best predictive lag: 2 days\n",
            " Cross-Correlation (Lead-Lag Analysis)\n",
            "Cross-Correlation Results:\n",
            "  Maximum correlation: -0.1415 at lag 7 days\n",
            "  Profitability LEADS sentiment by 7 days\n",
            " PATTERN DISCOVERY & INSIGHTS\n",
            "K-Means Clustering (Basic)\n",
            "K-Means clustering complete\n",
            "Cluster Distribution:\n",
            "cluster_kmeans\n",
            "0    27\n",
            "1     1\n",
            "2     4\n",
            "Name: count, dtype: int64\n",
            "Cluster Profiles:\n",
            "                 total_pnl             total_trades avg_position_size  \\\n",
            "                      mean         sum         mean              mean   \n",
            "cluster_kmeans                                                          \n",
            "0                145802.95  3936679.61      4409.67           4918.70   \n",
            "1                840422.56   840422.56     12236.00          34396.58   \n",
            "2               1379964.19  5519856.78     19981.75           6263.04   \n",
            "\n",
            "                total_volume Account  \n",
            "                        mean   count  \n",
            "cluster_kmeans                        \n",
            "0               1.888614e+07      27  \n",
            "1               4.208766e+08       1  \n",
            "2               6.509624e+07       4  \n",
            "  Cluster 0: BALANCED TRADERS\n",
            "    Members: 27\n",
            "    Avg PnL: $145,802.95\n",
            "  Cluster 1: WHALE TRADERS (Large Positions)\n",
            "    Members: 1\n",
            "    Avg PnL: $840,422.56\n",
            "  Cluster 2: HIGH FREQUENCY SCALPERS\n",
            "    Members: 4\n",
            "    Avg PnL: $1,379,964.19\n",
            "DBSCAN Clustering (Advanced - Density-based)\n",
            "DBSCAN clustering complete\n",
            "  Clusters found: 5\n",
            "  Outliers detected: 17\n",
            "  Outlier traders (exceptional performance):\n",
            "    Account 0xb1231a4a2d...: $2,143,382.60\n",
            "    Account 0x083384f897...: $1,600,229.82\n",
            "    Account 0xbaaaf6571a...: $940,163.81\n",
            " PCA Analysis (Advanced)\n",
            "PCA complete\n",
            "  PC1 explains: 43.75% variance\n",
            "  PC2 explains: 23.97% variance\n",
            "  Total explained: 67.72%\n",
            " Profitable Trader Patterns\n",
            "Comparison: Profitable vs Others\n",
            "  Profitable Traders: 8\n",
            "  Others: 24\n",
            "                   Profitable (Top 25%)        Others\n",
            "Avg Position Size          9.768490e+03  4.754409e+03\n",
            "Avg Trade Count            1.241825e+04  4.661583e+03\n",
            "Avg Volume                 9.190939e+07  1.899635e+07\n",
            "Profit Factor              1.814828e+02  1.586792e+02\n",
            " Statistical Significance Tests\n",
            "Position Size Difference:\n",
            "  Mann-Whitney U: 133.00\n",
            "  p-value: 0.113449\n",
            "  Result: Not Significant\n",
            "Sentiment Association with Profitability:\n",
            "  Chi-Square: 16097.61\n",
            "  p-value: 0.000000\n",
            "  Result: SIGNIFICANT\n",
            "Cluster Performance Difference:\n",
            "  F-statistic: 40.36\n",
            "  p-value: 0.000000\n",
            "  Result: SIGNIFICANT\n",
            " Behavioral Patterns in Different Market Conditions\n",
            "Average Position Size by Sentiment & Profitability:\n",
            "is_profitable     False     True \n",
            "classification                   \n",
            "Extreme Fear    7385.23   3848.97\n",
            "Extreme Greed   2910.02   3734.12\n",
            "Fear            6006.20   8947.89\n",
            "Greed           2965.72  10123.51\n",
            "Neutral         3702.10   5770.08\n",
            "Trade Frequency by Sentiment & Profitability:\n",
            "is_profitable   False  True \n",
            "classification              \n",
            "Extreme Fear     9082  12318\n",
            "Extreme Greed   30178   9814\n",
            "Fear            23791  38046\n",
            "Greed           30828  19475\n",
            "Neutral         17993  19693\n",
            "Saving results...\n",
            "Saved: csv_files/trader_metrics_clustered.csv\n",
            "Saved: csv_files/behavioral_patterns.csv\n",
            "Saved: csv_files/profitable_comparison.csv\n",
            "Creating visualizations...\n",
            "1. Creating sentiment profitability boxplot...\n",
            "  Saved: outputs/9_sentiment_profitability_boxplot.png\n",
            "2. Creating trader clusters PCA plot...\n",
            "  Saved: outputs/10_trader_clusters_pca.png\n",
            "3. Creating profitable comparison chart...\n",
            "  Saved: outputs/11_profitable_comparison.png\n",
            "4. Creating volume sentiment shift chart...\n",
            "  Saved: outputs/12_volume_sentiment_shift.png\n",
            "STEPS 4 & 5 COMPLETE\n",
            "New CSV Files:\n",
            "  - sentiment_correlation_results.csv\n",
            "  - trader_metrics_clustered.csv\n",
            "  - behavioral_patterns.csv\n",
            "  - profitable_comparison.csv\n",
            "New Visualizations:\n",
            "  - 9_sentiment_profitability_boxplot.png\n",
            "  - 10_trader_clusters_pca.png\n",
            "  - 11_profitable_comparison.png\n",
            "  - 12_volume_sentiment_shift.png\n"
          ]
        }
      ]
    }
  ]
}